apiVersion: "nuclio.io/v1"
kind: "NuclioFunction"
metadata:
  name: mxnet
  namespace: nuclio
spec:
  runtime: python
  handler: python_executioner:start_from_nuclio
  env:
    - name: DMLC_PS_ROOT_URI
      value: 127.0.0.1
      #value: 192.168.10.205
    - name: DMLC_PS_ROOT_PORT
      value: 9092
    - name: PS_VERBOSE
      value: 1
    - name: DMLC_NUM_SERVER
      value: 1
    - name: DMLC_NUM_WORKER
      value: 1
    - name: DMLC_ROLE
      value: worker
    - name: HDFSCLI_CONFIG
      value: /tmp/.hdfscli.cfg
    - name: HADOOP_USER_NAME
      value: franslukas
  build:
    noCache: true
    commands:
      - echo "[global]" >> /tmp/.hdfscli.cfg
      - echo "default.alias = dev" >> /tmp/.hdfscli.cfg
      - echo "[dev.alias]" >> /tmp/.hdfscli.cfg
      - echo "url = http://130.239.48.222:9870" >> /tmp/.hdfscli.cfg
      - echo "user = pirat" >> /tmp/.hdfscli.cfg
      - rm -rf DLScheduler
      - git clone https://github.com/Frans-Lukas/DLScheduler.git
      - apt-get update
      - apt-get -y install libopenblas-dev curl
      - curl -o /not_hotdog_validation-c0201740.rec https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/not_hotdog_validation-c0201740.rec
      - "pip install mxnet pillow keras dload numpy tensorflow hdfs"
